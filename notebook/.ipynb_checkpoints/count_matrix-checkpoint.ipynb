{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_columns = 300\n",
    "import sys\n",
    "sys.path.append(\"../fraud_detection/src/\")\n",
    "from util import s_to_time_format, string_to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"../dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def value_to_count(df_train, df_test):\n",
    "\n",
    "    # continuous_feats = [\"locdt\",\"conam\",\"loctm_hour_of_day\",\n",
    "    #                 \"loctm_minute_of_hour\",\"loctm_second_of_min\"]\n",
    "\n",
    "    # feats = [f for f in df_test.columns.tolist() if f not in continuous_feats]\n",
    "    feats = ['acqic', 'bacno', 'cano', 'conam', 'contp', 'csmcu', 'ecfg', 'etymd',\n",
    "       'flbmk', 'flg_3dsmk', 'hcefg', 'insfg', 'iterm', 'mcc',\n",
    "       'mchno', 'ovrlt', 'scity', 'stocn', 'stscd']\n",
    "\n",
    "    df = pd.concat([df_train[feats], df_test[feats]], axis = 0)\n",
    "    df_train_ = pd.DataFrame()\n",
    "    df_test_ = pd.DataFrame()\n",
    "    for f in tqdm(feats):\n",
    "        count_dict = df[f].value_counts(dropna = False).to_dict() \n",
    "        df_train_[f] = df_train[f].apply(lambda v: count_dict[v])\n",
    "        df_test_[f] = df_test[f].apply(lambda v: count_dict[v])\n",
    "    continuous_feats = ['locdt', 'loctm_hour_of_day', 'loctm_minute_of_hour', 'loctm_second_of_min']\n",
    "    for f in tqdm(continuous_feats):\n",
    "        df_train_[f] = df_train[f]\n",
    "        df_test_[f] = df_test[f]\n",
    "    df_train_[\"fraud_ind\"] = df_train[\"fraud_ind\"]\n",
    "    \n",
    "    return df_train_, df_test_\n",
    "\n",
    "def feature_normalization_auto(df_train, df_test, mode = \"train\"):\n",
    "    \"\"\"\n",
    "    return two inputs of autoencoder, one is for train and another one is for test\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "    feats = ['acqic', 'bacno', 'cano', 'conam', 'contp', 'csmcu', 'ecfg', 'etymd',\n",
    "       'flbmk', 'flg_3dsmk', 'hcefg', 'insfg', 'iterm', 'locdt', 'mcc',\n",
    "       'mchno', 'ovrlt', 'scity', 'stocn', 'stscd', 'loctm_hour_of_day',\n",
    "       'loctm_minute_of_hour', 'loctm_second_of_min']\n",
    "    scaler = MinMaxScaler()\n",
    "    df = pd.concat([df_train[feats], df_test[feats]], axis = 0)\n",
    "\n",
    "    data = df[feats]\n",
    "    scaler.fit(data)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        X_train = df_train[df_train.fraud_ind == 0]\n",
    "        \n",
    "        X_train = X_train[feats]\n",
    "        X_test = df_test[feats]\n",
    "        \n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    else:\n",
    "        X_train = scaler.transform(df_train[feats])\n",
    "        X_test = scaler.transform(df_test[feats])\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:16<00:00,  1.18it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 140.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    # pre-processing\n",
    "    df[\"loctm_\"] = df.loctm.astype(int).astype(str)\n",
    "    df.loctm_ = df.loctm_.apply(s_to_time_format).apply(string_to_datetime)\n",
    "    # time-related feature\n",
    "    df[\"loctm_hour_of_day\"] = df.loctm_.apply(lambda x: x.hour).astype('category')\n",
    "    df[\"loctm_minute_of_hour\"] = df.loctm_.apply(lambda x: x.minute)\n",
    "    df[\"loctm_second_of_min\"] = df.loctm_.apply(lambda x: x.second)\n",
    "    \n",
    "    # removed the columns no need\n",
    "    df.drop(columns = [\"loctm_\", \"loctm\",\"txkey\"], axis = 1, inplace = True)\n",
    "\n",
    "df_train_, df_test_ = value_to_count(df_train, df_test)\n",
    "\n",
    "\n",
    "X_train, X_test = feature_preprocessing_auto(df_train_, df_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acqic</th>\n",
       "      <th>bacno</th>\n",
       "      <th>cano</th>\n",
       "      <th>conam</th>\n",
       "      <th>contp</th>\n",
       "      <th>csmcu</th>\n",
       "      <th>ecfg</th>\n",
       "      <th>etymd</th>\n",
       "      <th>flbmk</th>\n",
       "      <th>flg_3dsmk</th>\n",
       "      <th>fraud_ind</th>\n",
       "      <th>hcefg</th>\n",
       "      <th>insfg</th>\n",
       "      <th>iterm</th>\n",
       "      <th>locdt</th>\n",
       "      <th>mcc</th>\n",
       "      <th>mchno</th>\n",
       "      <th>ovrlt</th>\n",
       "      <th>scity</th>\n",
       "      <th>stocn</th>\n",
       "      <th>stscd</th>\n",
       "      <th>loctm_hour_of_day</th>\n",
       "      <th>loctm_minute_of_hour</th>\n",
       "      <th>loctm_second_of_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6881</td>\n",
       "      <td>113261</td>\n",
       "      <td>38038</td>\n",
       "      <td>513.80</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>457</td>\n",
       "      <td>59333</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134508</td>\n",
       "      <td>45725</td>\n",
       "      <td>465.62</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5817</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6881</td>\n",
       "      <td>15408</td>\n",
       "      <td>188328</td>\n",
       "      <td>513.80</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>457</td>\n",
       "      <td>59333</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6716</td>\n",
       "      <td>157159</td>\n",
       "      <td>29967</td>\n",
       "      <td>1016.11</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>247</td>\n",
       "      <td>50436</td>\n",
       "      <td>N</td>\n",
       "      <td>3281</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5975</td>\n",
       "      <td>105985</td>\n",
       "      <td>81305</td>\n",
       "      <td>713.66</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>263</td>\n",
       "      <td>93775</td>\n",
       "      <td>N</td>\n",
       "      <td>5817</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1521782</td>\n",
       "      <td>6322</td>\n",
       "      <td>91008</td>\n",
       "      <td>15189</td>\n",
       "      <td>578.38</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>Y</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "      <td>38222</td>\n",
       "      <td>N</td>\n",
       "      <td>5817</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1521783</td>\n",
       "      <td>3226</td>\n",
       "      <td>145107</td>\n",
       "      <td>116252</td>\n",
       "      <td>435.32</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>Y</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>192</td>\n",
       "      <td>90135</td>\n",
       "      <td>N</td>\n",
       "      <td>1458</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1521784</td>\n",
       "      <td>6769</td>\n",
       "      <td>162168</td>\n",
       "      <td>93598</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>Y</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>373</td>\n",
       "      <td>79246</td>\n",
       "      <td>N</td>\n",
       "      <td>5817</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1521785</td>\n",
       "      <td>6032</td>\n",
       "      <td>45406</td>\n",
       "      <td>197460</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>373</td>\n",
       "      <td>79246</td>\n",
       "      <td>N</td>\n",
       "      <td>5817</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1521786</td>\n",
       "      <td>6716</td>\n",
       "      <td>48723</td>\n",
       "      <td>176440</td>\n",
       "      <td>406.59</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>251</td>\n",
       "      <td>69607</td>\n",
       "      <td>N</td>\n",
       "      <td>2310</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1521787 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         acqic   bacno    cano    conam  contp  csmcu ecfg  etymd flbmk  \\\n",
       "0         6881  113261   38038   513.80      5      0    N      0     N   \n",
       "1            0  134508   45725   465.62      5      0    N      2     N   \n",
       "2         6881   15408  188328   513.80      5      0    N      0     N   \n",
       "3         6716  157159   29967  1016.11      5     62    N      5     N   \n",
       "4         5975  105985   81305   713.66      5     62    N      4     N   \n",
       "...        ...     ...     ...      ...    ...    ...  ...    ...   ...   \n",
       "1521782   6322   91008   15189   578.38      5     75    Y      8   NaN   \n",
       "1521783   3226  145107  116252   435.32      5     75    Y      8   NaN   \n",
       "1521784   6769  162168   93598     1.38      5     75    Y      8   NaN   \n",
       "1521785   6032   45406  197460     1.38      5     75    Y      2   NaN   \n",
       "1521786   6716   48723  176440   406.59      5     75    N      5   NaN   \n",
       "\n",
       "        flg_3dsmk  fraud_ind  hcefg insfg  iterm  locdt  mcc  mchno ovrlt  \\\n",
       "0               N          0      5     N      0     33  457  59333     N   \n",
       "1               N          0      0     N      0      9  451      0     N   \n",
       "2               N          0      5     N      0      6  457  59333     N   \n",
       "3               N          0      5     N      0      5  247  50436     N   \n",
       "4               N          0      5     N      0      6  263  93775     N   \n",
       "...           ...        ...    ...   ...    ...    ...  ...    ...   ...   \n",
       "1521782       NaN          0      6     N      0      4  209  38222     N   \n",
       "1521783       NaN          0      6     N      0     13  192  90135     N   \n",
       "1521784       NaN          0      6     N      0     29  373  79246     N   \n",
       "1521785       NaN          0      6     N      0     24  373  79246     N   \n",
       "1521786       NaN          0      6     N      0     13  251  69607     N   \n",
       "\n",
       "         scity  stocn  stscd loctm_hour_of_day  loctm_minute_of_hour  \\\n",
       "0            0    102      0                17                    26   \n",
       "1         5817    102      0                10                    51   \n",
       "2            0    102      0                15                    24   \n",
       "3         3281    102      0                17                    29   \n",
       "4         5817    102      0                18                    21   \n",
       "...        ...    ...    ...               ...                   ...   \n",
       "1521782   5817    102      0                19                    16   \n",
       "1521783   1458    102      0                10                    23   \n",
       "1521784   5817    102      0                23                    46   \n",
       "1521785   5817    102      0                21                    52   \n",
       "1521786   2310    102      0                16                    36   \n",
       "\n",
       "         loctm_second_of_min  \n",
       "0                         52  \n",
       "1                         14  \n",
       "2                         58  \n",
       "3                         46  \n",
       "4                         29  \n",
       "...                      ...  \n",
       "1521782                   42  \n",
       "1521783                   38  \n",
       "1521784                   18  \n",
       "1521785                   18  \n",
       "1521786                    3  \n",
       "\n",
       "[1521787 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39383468, 0.07078853, 0.07078853, 1.        , 1.        ,\n",
       "       0.14213743, 1.        , 0.32460156, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.26890756, 0.53854708,\n",
       "       0.64663047, 1.        , 0.19615079, 1.        , 1.        ,\n",
       "       0.73913043, 0.44067797, 0.88135593])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.93834678e-01, 8.96057348e-03, 8.96057348e-03, ...,\n",
       "        9.13043478e-01, 8.98305085e-01, 4.74576271e-01],\n",
       "       [3.93834678e-01, 8.96057348e-03, 8.96057348e-03, ...,\n",
       "        9.56521739e-01, 3.38983051e-01, 1.18644068e-01],\n",
       "       [3.93834678e-01, 8.96057348e-03, 8.96057348e-03, ...,\n",
       "        7.39130435e-01, 0.00000000e+00, 2.20338983e-01],\n",
       "       ...,\n",
       "       [4.97652670e-01, 8.96057348e-04, 0.00000000e+00, ...,\n",
       "        7.82608696e-01, 8.30508475e-01, 3.55932203e-01],\n",
       "       [2.18002839e-01, 8.96057348e-04, 0.00000000e+00, ...,\n",
       "        6.08695652e-01, 7.45762712e-01, 5.76271186e-01],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        6.95652174e-01, 4.74576271e-01, 6.77966102e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1501432, 23), (421665, 23))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras import regularizers\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "def autoencoder(input_dim, encoding_dim):\n",
    "    \"\"\"\n",
    "    architecture of autoencoder, we consider this as a dimension reduction method. \n",
    "    encoding_dim: int\n",
    "    input_dim: int.\n",
    "    \"\"\"\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.models import Model\n",
    "    \n",
    "    input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "    encoder = Dense(encoding_dim, activation=\"tanh\",\n",
    "                    activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "    encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "\n",
    "    decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "    decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "def build_model(autoencoder,X_train,X_test,nb_epoch = 100,batch_size = 32):\n",
    "    \"\"\"\n",
    "    X_train: data only including normal transation data\n",
    "\n",
    "    X_test: data both including fradulant and normal data \n",
    "    \"\"\"\n",
    "    autoencoder.compile(optimizer='adam',\n",
    "                        loss='mean_squared_error',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=\"../fraud_detection/models/auto_encoder.h5\",\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', \n",
    "                                  min_delta=0, \n",
    "                                  patience=5, \n",
    "                                  verbose=1, \n",
    "                                  mode='auto', \n",
    "                                  baseline=None, \n",
    "                                  restore_best_weights=False)\n",
    "\n",
    "#     tensorboard = TensorBoard(log_dir='/media/old-tf-hackers-7/logs',\n",
    "#                               histogram_freq=0,\n",
    "#                               write_graph=True,\n",
    "#                               write_images=True)\n",
    "    history = autoencoder.fit(X_train, X_train,\n",
    "                        epochs=nb_epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_test, X_test),\n",
    "                        verbose=1,\n",
    "                        callbacks=[checkpointer, earlystopper]).history\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of raw features 23\n",
      "number of normal data 1501432\n",
      "WARNING:tensorflow:From /ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                336       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 105       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 23)                184       \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /ldap_home/yunrui.li/.pyenv/versions/3.6.5/envs/fraud/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 1501432 samples, validate on 421665 samples\n",
      "Epoch 1/100\n",
      "1501432/1501432 [==============================] - 155s 103us/step - loss: 0.0251 - acc: 0.1030 - val_loss: 42915.0805 - val_acc: 0.0503\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 42915.08052, saving model to ../fraud_detection/models/auto_encoder.h5\n",
      "Epoch 2/100\n",
      "1501432/1501432 [==============================] - 153s 102us/step - loss: 0.0137 - acc: 0.0918 - val_loss: 42919.6691 - val_acc: 0.0503\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 42915.08052\n",
      "Epoch 3/100\n",
      "1501432/1501432 [==============================] - 153s 102us/step - loss: 0.0133 - acc: 0.0872 - val_loss: 42925.8295 - val_acc: 0.0503\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 42915.08052\n",
      "Epoch 4/100\n",
      "1501432/1501432 [==============================] - 158s 105us/step - loss: 0.0131 - acc: 0.0864 - val_loss: 42923.3327 - val_acc: 0.0503\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 42915.08052\n",
      "Epoch 5/100\n",
      "1501432/1501432 [==============================] - 156s 104us/step - loss: 0.0130 - acc: 0.0866 - val_loss: 42916.9475 - val_acc: 0.0503\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 42915.08052\n",
      "Epoch 6/100\n",
      "1501432/1501432 [==============================] - 154s 103us/step - loss: 0.0122 - acc: 0.0726 - val_loss: 42926.3258 - val_acc: 0.0500\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 42915.08052\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 14\n",
    "print ('number of raw features', input_dim)\n",
    "print ('number of normal data', X_train.shape[0])\n",
    "\n",
    "\n",
    "autoencoder = autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "print (autoencoder.summary())\n",
    "\n",
    "history = build_model(autoencoder,X_train,X_test,nb_epoch = 100,batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [42915.08051946187,\n",
       "  42919.66911671958,\n",
       "  42925.829506698195,\n",
       "  42923.33270712955,\n",
       "  42916.94745477529,\n",
       "  42926.325847135224],\n",
       " 'val_acc': [0.050293479420867274,\n",
       "  0.0502816216664888,\n",
       "  0.05027687856473741,\n",
       "  0.0502816216664888,\n",
       "  0.050283993217364494,\n",
       "  0.049999407112281076],\n",
       " 'loss': [0.02505599849484288,\n",
       "  0.013667578810347785,\n",
       "  0.01330996551152277,\n",
       "  0.013122114607612494,\n",
       "  0.013018962832506462,\n",
       "  0.012193644494575929],\n",
       " 'acc': [0.1030243127894301,\n",
       "  0.09181501393340465,\n",
       "  0.08717744126944117,\n",
       "  0.08642149627821973,\n",
       "  0.08660598681793767,\n",
       "  0.07259935847912513]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
