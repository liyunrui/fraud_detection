{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sys\n",
    "sys.path.append(\"../fraud_detection/src/\")\n",
    "from util import lgb_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train application df shape: (1521787, 477)\n",
      "Test application df shape: (421665, 476)\n",
      "Load train/test features extracted - done in 124s\n",
      "Train application df shape: (1521787, 487)\n",
      "Test application df shape: (421665, 486)\n",
      "Add bacno time aggregate average feature - done in 236s\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../fraud_detection/src/\")\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "from contextlib import contextmanager\n",
    "import gc \n",
    "from util import s_to_time_format, string_to_datetime, hour_to_range, kfold_lightgbm, kfold_xgb\n",
    "from util import rolling_stats_target_by_cols\n",
    "#from util import _time_elapsed_between_last_transactions,time_elapsed_between_last_transactions\n",
    "#from util import num_transaction_in_past_n_days\n",
    "#from util import add_auto_encoder_feature\n",
    "#from util import group_target_by_cols_split_by_users\n",
    "from time import strftime, localtime\n",
    "import logging\n",
    "import sys\n",
    "from config import Configs\n",
    "\n",
    "# logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "#log_file = '{}-{}-{}.log'.format(opt.model_name, opt.dataset, strftime(\"%y%m%d-%H%M\", localtime()))\n",
    "log_file = '../fraud_detection/result/fs_{}.log'.format(strftime(\"%y%m%d-%H%M\", localtime()))\n",
    "logger.addHandler(logging.FileHandler(log_file))\n",
    "\n",
    "def group_target_by_cols(df_train, df_test, recipe):\n",
    "    df = pd.concat([df_train, df_test], axis = 0)\n",
    "    for m in range(len(recipe)):\n",
    "        cols = recipe[m][0]\n",
    "        for n in range(len(recipe[m][1])):\n",
    "            target = recipe[m][1][n][0]\n",
    "            method = recipe[m][1][n][1]\n",
    "            name_grouped_target = method+\"_\"+target+'_BY_'+'_'.join(cols)\n",
    "            tmp = df[cols + [target]].groupby(cols).agg(method)\n",
    "            tmp = tmp.reset_index().rename(index=str, columns={target: name_grouped_target})\n",
    "            df_train = df_train.merge(tmp, how='left', on=cols)\n",
    "            df_test = df_test.merge(tmp, how='left', on=cols)\n",
    "\n",
    "        # reduced memory    \n",
    "        del tmp\n",
    "        gc.collect()\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    logger.info(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "    \n",
    "def main(args):\n",
    "    if args.load_feature == True:\n",
    "        with timer(\"Load train/test features extracted\"):\n",
    "            #-------------------------\n",
    "            # load dataset\n",
    "            #-------------------------\n",
    "            df_train = pd.read_csv(\"../fraud_detection/features/train.csv\")\n",
    "            df_test = pd.read_csv(\"../fraud_detection/features/test.csv\")\n",
    "\n",
    "            #-------------------------\n",
    "            # pre-processing\n",
    "            #-------------------------\n",
    "\n",
    "            for cat in Configs.CATEGORY:\n",
    "                df_train[cat] = df_train[cat].astype('category') #.cat.codes\n",
    "                df_test[cat] = df_test[cat].astype('category')\n",
    "            for df in [df_train, df_test]:\n",
    "                df[\"hour_range\"] = df[\"hour_range\"].astype('category')\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))     \n",
    "\n",
    "    else:\n",
    "        with timer(\"Process train/test application\"):\n",
    "            #-------------------------\n",
    "            # load dataset\n",
    "            #-------------------------\n",
    "            df_train = pd.read_csv(args.train_file)\n",
    "            df_test = pd.read_csv(args.test_file)\n",
    "\n",
    "            #-------------------------\n",
    "            # pre-processing\n",
    "            #-------------------------\n",
    "\n",
    "            for cat in Configs.CATEGORY:\n",
    "                df_train[cat] = df_train[cat].astype('category') #.cat.codes\n",
    "                df_test[cat] = df_test[cat].astype('category')\n",
    "                \n",
    "            for df in [df_train, df_test]:\n",
    "                # pre-processing\n",
    "                df[\"loctm_\"] = df.loctm.astype(int).astype(str)\n",
    "                df.loctm_ = df.loctm_.apply(s_to_time_format).apply(string_to_datetime)\n",
    "                # # time-related feature\n",
    "                df[\"loctm_hour_of_day\"] = df.loctm_.apply(lambda x: x.hour).astype('category')\n",
    "                df[\"loctm_minute_of_hour\"] = df.loctm_.apply(lambda x: x.minute)\n",
    "                df[\"loctm_second_of_min\"] = df.loctm_.apply(lambda x: x.second)\n",
    "                # df[\"loctm_absolute_time\"] = [h*60+m for h,m in zip(df.loctm_hour_of_day,df.loctm_minute_of_hour)]\n",
    "                df[\"hour_range\"] = df.loctm_.apply(lambda x: hour_to_range(x.hour)).astype(\"category\")\n",
    "                # removed the columns no need\n",
    "                df.drop(columns = [\"loctm_\"], axis = 1, inplace = True)\n",
    "                # auxiliary fields\n",
    "                df[\"day_hr_min\"] = [\"{}:{}:{}\".format(i,j,k) for i,j,k in zip(df.locdt,df.loctm_hour_of_day,df.loctm_minute_of_hour)]\n",
    "                df[\"day_hr_min_sec\"] = [\"{}:{}:{}:{}\".format(i,j,k,z) for i,j,k,z in zip(df.locdt,df.loctm_hour_of_day,df.loctm_minute_of_hour,df.loctm_second_of_min)]\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add bacno/cano feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.CONAM_AGG_RECIPE_1)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add iterm-related feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.ITERM_AGG_RECIPE)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add conam-related feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.CONAM_AGG_RECIPE_2)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add hour-related feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.HOUR_AGG_RECIPE)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add cano/conam feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.CANO_CONAM_COUNT_RECIPE)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add cano/bacno latent feature\"):\n",
    "            df = pd.read_csv(\"../fraud_detection/features/bacno_latent_features_w_cano.csv\")\n",
    "            df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "            df = pd.read_csv(\"../fraud_detection/features/bacno_cano_latent_features.csv\")\n",
    "            df_train = df_train.merge(df, on = \"cano\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"cano\", how = \"left\")\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add locdt-related feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.LOCDT_CONAM_RECIPE)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add mchno-related feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.MCHNO_CONAM_RECIPE)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add scity-related feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.SCITY_CONAM_RECIPE)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add stocn-related feature\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.STOCN_CONAM_RECIPE)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add mchno/bacno latent feature\"):\n",
    "            df = pd.read_csv(\"../fraud_detection/features/bacno_latent_features_w_mchno.csv\")\n",
    "            df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "            df = pd.read_csv(\"../fraud_detection/features/bacno_mchno_latent_features.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add time second-level feature on bacno\"):\n",
    "            df_train, df_test = group_target_by_cols(\n",
    "                df_train, \n",
    "                df_test, \n",
    "                Configs.HOUR_AGG_SEC_LEVEL_RECIPE_BACNO,\n",
    "                )\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add time second-level feature on cano\"):\n",
    "            df_train, df_test = group_target_by_cols(\n",
    "                df_train, \n",
    "                df_test, \n",
    "                Configs.HOUR_AGG_SEC_LEVEL_RECIPE_CANO,\n",
    "                )\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add time second-level feature on mchno\"):\n",
    "            df_train, df_test = group_target_by_cols(\n",
    "                df_train, \n",
    "                df_test, \n",
    "                Configs.HOUR_AGG_SEC_LEVEL_RECIPE_MCHNO,\n",
    "                )\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add time second-level feature on csmcu/stocn/scity\"):\n",
    "            df_train, df_test = group_target_by_cols(\n",
    "                df_train, \n",
    "                df_test, \n",
    "                Configs.HOUR_AGG_SEC_LEVEL_RECIPE,\n",
    "                )\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add time second-level feature on acqic/csmcu/stocn/scity\"):\n",
    "            df_train, df_test = group_target_by_cols(\n",
    "                df_train, \n",
    "                df_test, \n",
    "                Configs.HOUR_AGG_SEC_LEVEL_RECIPE_2,\n",
    "                )\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add conam-related feature v3\"):\n",
    "            df_train, df_test = group_target_by_cols(\n",
    "                df_train, \n",
    "                df_test, \n",
    "                Configs.CONAM_AGG_RECIPE_3,\n",
    "                )\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add locdt-related feature v2\"):\n",
    "            df_train, df_test = group_target_by_cols(df_train, df_test, Configs.LOCDT_CONAM_RECIPE_2)\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add conam-related feature v4\"):\n",
    "            df_train, df_test = group_target_by_cols(\n",
    "                df_train, \n",
    "                df_test, \n",
    "                Configs.CONAM_AGG_RECIPE_4,\n",
    "                )\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add cano/mchno latent feature\"):\n",
    "            df = pd.read_csv(\"../fraud_detection/features/cano_latent_features_w_mchno.csv\")\n",
    "            df_train = df_train.merge(df, on = \"cano\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"cano\", how = \"left\")\n",
    "            df = pd.read_csv(\"../fraud_detection/features/cano_mchno_latent_features.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add cano/locdt latent feature\"):\n",
    "            df = pd.read_csv(\"../fraud_detection/features/cano_latent_features_w_locdt.csv\")\n",
    "            df_train = df_train.merge(df, on = \"cano\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"cano\", how = \"left\")\n",
    "            df = pd.read_csv(\"../fraud_detection/features/cano_locdt_latent_features.csv\")\n",
    "            df_train = df_train.merge(df, on = \"locdt\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"locdt\", how = \"left\")\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add mchno/locdt latent feature\"):\n",
    "            df = pd.read_csv(\"../fraud_detection/features/mchno_latent_features_w_locdt.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df = pd.read_csv(\"../fraud_detection/features/mchno_locdt_latent_features.csv\")\n",
    "            df_train = df_train.merge(df, on = \"locdt\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"locdt\", how = \"left\")\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "        with timer(\"Add mchno time aggregate average feature\"):\n",
    "            # df = pd.read_csv(\"../features/average_mchno_time_agg.csv\")\n",
    "            # df_train = df_train.merge(df, on = \"txkey\", how = \"left\")\n",
    "            # df_test = df_test.merge(df, on = \"txkey\", how = \"left\")\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_mean_conam_in_past_7_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_mean_conam_in_past_14_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_std_conam_in_past_7_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_std_conam_in_past_14_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_min_conam_in_past_7_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_min_conam_in_past_14_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_max_conam_in_past_7_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_max_conam_in_past_14_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_median_conam_in_past_7_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            df = pd.read_csv(\"../fraud_detection/features/average_mchno_median_conam_in_past_14_days.csv\")\n",
    "            df_train = df_train.merge(df, on = \"mchno\", how = \"left\")\n",
    "            df_test = df_test.merge(df, on = \"mchno\", how = \"left\")\n",
    "\n",
    "            logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "            logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "    with timer(\"Add bacno time aggregate average feature\"):\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_min_conam_in_past_7_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_max_conam_in_past_7_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_mean_conam_in_past_7_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_median_conam_in_past_7_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_std_conam_in_past_7_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_min_conam_in_past_14_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_max_conam_in_past_14_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_mean_conam_in_past_14_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_median_conam_in_past_14_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        df = pd.read_csv(\"../fraud_detection/features/average_bacno_std_conam_in_past_14_days.csv\").iloc[:,1:]\n",
    "        df_train = df_train.merge(df, on = \"bacno\", how = \"left\")\n",
    "        df_test = df_test.merge(df, on = \"bacno\", how = \"left\")\n",
    "\n",
    "        logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "        logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "#     with timer(\"Add mcc time aggregate average feature\"):\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/average_mcc_median_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = \"mcc\", how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = \"mcc\", how = \"left\")\n",
    "\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/average_mcc_max_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = \"mcc\", how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = \"mcc\", how = \"left\")\n",
    "\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/average_mcc_min_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = \"mcc\", how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = \"mcc\", how = \"left\")\n",
    "\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/average_mcc_mean_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = \"mcc\", how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = \"mcc\", how = \"left\")\n",
    "\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/average_mcc_std_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = \"mcc\", how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = \"mcc\", how = \"left\")\n",
    "\n",
    "#         logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "#         logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "#     with timer(\"Add scity time aggregate feature\"):\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/scity_mean_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = [\"scity\",\"locdt\"], how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = [\"scity\",\"locdt\"], how = \"left\")\n",
    "\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/scity_mean_conam_in_past_14_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = [\"scity\",\"locdt\"], how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = [\"scity\",\"locdt\"], how = \"left\")\n",
    "\n",
    "#         logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "#         logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "#     with timer(\"Add stocn time aggregate feature\"):\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/stocn_mean_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = [\"stocn\",\"locdt\"], how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = [\"stocn\",\"locdt\"], how = \"left\")\n",
    "\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/stocn_mean_conam_in_past_14_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = [\"stocn\",\"locdt\"], how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = [\"stocn\",\"locdt\"], how = \"left\")\n",
    "        \n",
    "#         logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "#         logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "#     with timer(\"Add acqic time aggregate feature\"):\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/acqic_mean_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = [\"acqic\",\"locdt\"], how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = [\"acqic\",\"locdt\"], how = \"left\")\n",
    "\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/acqic_mean_conam_in_past_14_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = [\"acqic\",\"locdt\"], how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = [\"acqic\",\"locdt\"], how = \"left\")\n",
    "        \n",
    "#         logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "#         logger.info(\"Test application df shape: {}\".format(df_test.shape))\n",
    "\n",
    "#     with timer(\"Add mchno time aggregate feature\"):\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/mchno_mean_conam_in_past_7_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = [\"mchno\",\"locdt\"], how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = [\"mchno\",\"locdt\"], how = \"left\")\n",
    "\n",
    "#         df = pd.read_csv(\"../fraud_detection/features/mchno_mean_conam_in_past_14_days.csv\")\n",
    "#         df_train = df_train.merge(df, on = [\"mchno\",\"locdt\"], how = \"left\")\n",
    "#         df_test = df_test.merge(df, on = [\"mchno\",\"locdt\"], how = \"left\")\n",
    "        \n",
    "#         logger.info(\"Train application df shape: {}\".format(df_train.shape))\n",
    "#         logger.info(\"Test application df shape: {}\".format(df_test.shape))   \n",
    "        \n",
    "    return df_train, df_test\n",
    "\n",
    "args = {\n",
    " \"train_file\":\"/data/yunrui_li/fraud/dataset/train.csv\",\n",
    " \"test_file\":\"/data/yunrui_li/fraud/dataset/test.csv\",\n",
    " \"result_path\":\"/data/yunrui_li/fraud/fraud_detection/result/submission.csv\",\n",
    " \"feature_selection\":True,\n",
    " \"feature_importance_plot\": False,\n",
    " \"SEED\": 1030,\n",
    " \"NUM_FOLDS\": 5, # 5\n",
    " \"CPU_USE_RATE\":1.0,\n",
    " \"STRATIFIED\": True,\n",
    " \"NUM_LEAVES\":31,\n",
    " \"COLSAMPLE_BYTREE\":1.0,\n",
    " \"SUBSAMPLE\": 1.0,\n",
    " \"SUBSAMPLE_FREQ\": 0,\n",
    " \"MAX_DEPTH\": -1,\n",
    " \"REG_ALPHA\": 0.0,\n",
    " \"REG_LAMBDA\": 0.0,\n",
    " \"MIN_SPLIT_GAIN\": 0.0,\n",
    " \"MIN_CHILD_WEIGHT\": 0.001,\n",
    " \"MAX_BIN\": 255,\n",
    " \"SCALE_POS_WEIGHT\": 3,\n",
    " \"TEST_NULL_HYPO\":False,\n",
    " \"model\": \"lgb\",\n",
    " \"ensemble\":False,\n",
    " \"seed\":1030,\n",
    " \"load_feature\": True\n",
    "}\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "args = AttrDict(args)\n",
    "df_train, df_test = main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    # drop random features (by null hypothesis)\n",
    "    df.drop(Configs.FEATURE_GRAVEYARD, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "    # drop unused features features_with_no_imp_at_least_twice\n",
    "    df.drop(Configs.FEATURE_USELESSNESS, axis=1, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in df_train.columns if f not in [\"fraud_ind\"]]\n",
    "X,y = df_train[feats], df_train.fraud_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1521787, 479), (1521787,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | scale_... |\n",
      "-------------------------------------------------------------\n",
      "{'binary_logloss-mean': [0.13200305084554537, 0.1307906566073484, 0.12166192684724164, 0.12632001534631138, 0.11418440268295693, 0.11211154468037596, 0.10940964765671739, 0.10761125451023013, 0.10757863139527961, 0.10590601494524292, 0.1042995945407261, 0.10446240848229124, 0.10411454306724317, 0.10258792476327812], 'binary_logloss-stdv': [0.001780942368420147, 0.0071818964074741665, 0.0081894206406047, 0.020090952517396878, 0.011714045999349908, 0.009456610819359043, 0.009403172049261447, 0.009154416649585152, 0.009582605574448708, 0.009571413624047146, 0.008895079159472422, 0.009432073010574438, 0.008683230372629388, 0.006993704586171763], 'f1-mean': [0.4591369804474138, 0.45474197314869685, 0.48807263074473906, 0.4937311281949549, 0.5284759384269575, 0.5395342406559379, 0.5424374332453109, 0.544653020910084, 0.5451824656496458, 0.5515105806544852, 0.5567360662974787, 0.5598986351806272, 0.5624044578829503, 0.5626934197263826], 'f1-stdv': [0.02135349713009301, 0.031222928952282458, 0.026567714676200366, 0.025969143967559036, 0.010761389060532079, 0.005907835556760489, 0.008204033161450621, 0.008144530412597628, 0.013488534846296498, 0.010730936479913942, 0.01018493218554931, 0.01063806371470921, 0.009241822393570697, 0.009800862958374602]}\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5627  \u001b[0m | \u001b[0m 0.8646  \u001b[0m | \u001b[0m 0.9146  \u001b[0m | \u001b[0m 6.425   \u001b[0m |\n",
      "{'binary_logloss-mean': [0.13917114776317555, 0.1402596992243086, 0.1274764860092495, 0.12703979803972287, 0.12023545292090516, 0.11450303829285582, 0.11092230982230758, 0.10955286890351243, 0.10680151536476938, 0.1067711216003511, 0.10575822234297187, 0.10569196098621654, 0.10647438534093848, 0.10557071933242516], 'binary_logloss-stdv': [0.0015941731305031378, 0.011459759943306154, 0.00808464019075379, 0.018166056861917683, 0.01068990102795104, 0.007140738107430299, 0.005261415684465701, 0.005063781370759098, 0.007666020044912488, 0.007678948830341599, 0.006898413644539747, 0.00706296596913962, 0.0067883947571889406, 0.007541042557610313], 'f1-mean': [0.4818212520071265, 0.4611810795341536, 0.48593525896174283, 0.4893590180647089, 0.4970632737867384, 0.5107818939408616, 0.5194811802101367, 0.5249700495933152, 0.5343445020688781, 0.5389999675177604, 0.5420646601687805, 0.5444719634562177, 0.5461388373252227, 0.5486045862668385], 'f1-stdv': [0.0043023959838716435, 0.02248628823894011, 0.008216708404190427, 0.01526859576839954, 0.004786434656373414, 0.011321078560423492, 0.013585219675853447, 0.01013495901758694, 0.0033976809808900117, 0.0059403300911448865, 0.0050301980693906595, 0.0063248729826858065, 0.006260905789568906, 0.007039476019434223]}\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5486  \u001b[0m | \u001b[0m 0.8635  \u001b[0m | \u001b[0m 0.8271  \u001b[0m | \u001b[0m 6.813   \u001b[0m |\n",
      "{'binary_logloss-mean': [0.1768314445697894, 0.21943830479649135, 0.18141167661142438, 0.16968486259189872, 0.15910990378051548, 0.15380696287301482, 0.1505878728834402, 0.14818642149980693, 0.14694038274591698, 0.14558879945295797, 0.14619801068080657, 0.14577926018397971, 0.14547600331735072, 0.14278107578275243], 'binary_logloss-stdv': [0.0036240617433350394, 0.03279354881077654, 0.01287800991809786, 0.0155506907633002, 0.012854955722227706, 0.014650673841711698, 0.018063815376319705, 0.01746497722424134, 0.018023440512187683, 0.01778452643072074, 0.016874315344047663, 0.016706580783238584, 0.015587005218067386, 0.017082122707644004], 'f1-mean': [0.4107998021469551, 0.3617735932681567, 0.43700709879683153, 0.4469689136194459, 0.45333743698048395, 0.45885040123275633, 0.46516121857464954, 0.46906693714436354, 0.47354137322265133, 0.47763458608436515, 0.48085953528895986, 0.48805077006516695, 0.4869334782037452, 0.4920060195364611], 'f1-stdv': [0.018016743923907976, 0.023697371512388116, 0.013655735826534213, 0.013303795136971625, 0.012288713265631438, 0.011750335025670347, 0.011765019133927634, 0.01172269507671224, 0.010813076664132013, 0.010904317909075048, 0.01187118610995263, 0.005125488294735197, 0.008006572699286027, 0.0065023117602583695]}\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.492   \u001b[0m | \u001b[0m 0.8313  \u001b[0m | \u001b[0m 0.9675  \u001b[0m | \u001b[0m 9.673   \u001b[0m |\n",
      "{'binary_logloss-mean': [0.1195958183864658, 0.13844733426179645, 0.11713861108152987, 0.1125313422814181, 0.1108573525334279, 0.10799961586012286, 0.1076266522721403, 0.10639853269588528, 0.10384937378613142, 0.10324951187545865, 0.10221201868978422, 0.10255340549426646, 0.10200130580971208, 0.10256651616560708, 0.10206076326423771, 0.10198705958513613], 'binary_logloss-stdv': [0.0029262956616942803, 0.026050205860241118, 0.01135350876201069, 0.011311291372755435, 0.012467665695217957, 0.012151470567892978, 0.011710817011811196, 0.01166957694816869, 0.011841174508799264, 0.011985228401239088, 0.012421827801754699, 0.012835508344709185, 0.01260325598479423, 0.01307031031224544, 0.012597116183532651, 0.012035934340505329], 'f1-mean': [0.4836873326379695, 0.453247069014854, 0.5036510544164228, 0.5252394452896146, 0.5337286967750193, 0.5416692609755158, 0.545686279257483, 0.5471513128825105, 0.5516712041029128, 0.5564839112895306, 0.5615698631327207, 0.565034677754681, 0.5702754124653528, 0.5718090298097713, 0.5729017480604902, 0.5751751329079952], 'f1-stdv': [0.01490596818039907, 0.03167578503202885, 0.02125425731855635, 0.011865813977845661, 0.008072158292446348, 0.013715464840068506, 0.015505843134409173, 0.013230554210739329, 0.014299168893037659, 0.010254814421395347, 0.01160594923657442, 0.011251760718483822, 0.009511838567027638, 0.008783622319824482, 0.010961907577062578, 0.010344079859875767]}\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.5752  \u001b[0m | \u001b[95m 0.815   \u001b[0m | \u001b[95m 0.9375  \u001b[0m | \u001b[95m 5.76    \u001b[0m |\n",
      "{'binary_logloss-mean': [0.05395935211134929], 'binary_logloss-stdv': [0.002202262795476048], 'f1-mean': [0.6050019642458132], 'f1-stdv': [0.01904604186456974]}\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.605   \u001b[0m | \u001b[95m 0.8704  \u001b[0m | \u001b[95m 0.9777  \u001b[0m | \u001b[95m 1.639   \u001b[0m |\n",
      "{'binary_logloss-mean': [0.16125783887539905, 0.16056713201731249, 0.1472776562718306, 0.1400191457950662, 0.13500840146380616, 0.13076677516782234, 0.12928588040278166, 0.1247695114293991, 0.12481719100967284, 0.12473516127706888, 0.12375974048159415, 0.12331212248334518, 0.12302608866507021, 0.12301332480016938], 'binary_logloss-stdv': [0.0038508105693104326, 0.00991427195725401, 0.005984919401752587, 0.007442484429905537, 0.007206428754869635, 0.005874883755195085, 0.0065479599819489994, 0.008817487309888449, 0.014081314048388473, 0.012979555592777928, 0.013273048753837198, 0.012447145646859989, 0.012195019241992955, 0.010812751125539227], 'f1-mean': [0.43084773651599456, 0.4121489876211125, 0.4284439682397599, 0.4328596141150758, 0.441533135861759, 0.4442875944402199, 0.45015912865279856, 0.4735913700685691, 0.48826686133107716, 0.4943934047423995, 0.5043346028168784, 0.5134833716467857, 0.517685325477234, 0.5215462758579192], 'f1-stdv': [0.012862311962046916, 0.016304011976534267, 0.015066657628717674, 0.016176733305495232, 0.012385576211281142, 0.013667445815609771, 0.015524977156677002, 0.01811637071002501, 0.021567940210967754, 0.02158358293505551, 0.023116287773680248, 0.020702229937079784, 0.022351380291589475, 0.017078675617410208]}\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5215  \u001b[0m | \u001b[0m 0.7261  \u001b[0m | \u001b[0m 0.7061  \u001b[0m | \u001b[0m 8.494   \u001b[0m |\n",
      "{'binary_logloss-mean': [0.17797134649729754, 0.2391057097403218, 0.18763589292370994, 0.17810214448625158, 0.17282443421663768, 0.16883027428237618, 0.16569019391027978, 0.16203478188921983, 0.1615333029421478, 0.16280267210946842, 0.16016692945678343, 0.1605292351166307, 0.16077286501615756, 0.15841398378085564], 'binary_logloss-stdv': [0.004315277445979834, 0.014916054131221716, 0.008738154859705125, 0.007881442636624849, 0.01024348926565562, 0.011592217281141143, 0.010627402850381376, 0.011254529306342338, 0.014445072185147645, 0.016718244094748567, 0.010342052065453461, 0.010283728279374784, 0.010334031344493408, 0.011337709865812928], 'f1-mean': [0.4126034651192084, 0.3380423840544865, 0.43596448331455945, 0.4367310142563129, 0.44958604659259327, 0.4524347952417306, 0.45711841653016505, 0.4579771315788518, 0.4603918845608585, 0.4658136897541983, 0.472263251135015, 0.4749697551376538, 0.4766597121802797, 0.48453160614338014], 'f1-stdv': [0.01825708820203889, 0.012975791923628192, 0.015699176376270673, 0.02116507427508342, 0.015827514367260456, 0.012336309135490232, 0.013641849950334949, 0.012943554206542057, 0.02028763485543802, 0.017256909401266306, 0.015624242371066587, 0.017758052577745816, 0.016824279077122112, 0.014318617443456968]}\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.4845  \u001b[0m | \u001b[0m 0.9334  \u001b[0m | \u001b[0m 0.961   \u001b[0m | \u001b[0m 9.808   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'binary_logloss-mean': [0.15356786946498957, 0.1548232446872609, 0.14175949379802322, 0.139705409234453, 0.12906370457927854, 0.12498516228020842, 0.12150404560549832, 0.11940711363110024, 0.12460308323037732, 0.11979425490296935, 0.11676033946141251, 0.11662161672958675, 0.11607351129188133, 0.11632210312683536, 0.11628347083795551, 0.11508601066520023], 'binary_logloss-stdv': [0.002664980625136717, 0.01638185983484908, 0.009197371134259941, 0.014079730552809998, 0.010932653674583343, 0.012293462619323133, 0.011576063474246265, 0.011959579269350339, 0.015329954367691575, 0.010386588353150017, 0.00999101181394272, 0.010189939216715864, 0.009578726404631324, 0.009646006854327158, 0.009056416269273728, 0.007806896286281986], 'f1-mean': [0.46692127483013524, 0.440957288484275, 0.4792236258646848, 0.4798887475399325, 0.49148824854310114, 0.4925273100892066, 0.4961304199125342, 0.49790565205614107, 0.49520135206454113, 0.5017253370227758, 0.5083572051018967, 0.5137700690609666, 0.5176400279227067, 0.5216967326588426, 0.5241681536048882, 0.5211580838914099], 'f1-stdv': [0.017070115090298925, 0.029481459908457252, 0.014843890842676821, 0.016232276868117554, 0.012990482303461304, 0.014140028736958384, 0.013969100909101924, 0.01166780019668873, 0.025638453578041523, 0.014001345512839408, 0.010062568534320894, 0.011389225235691166, 0.0133055011928646, 0.015376163176387835, 0.016774083269095668, 0.01808248487215195]}\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5242  \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.8384  \u001b[0m | \u001b[0m 8.025   \u001b[0m |\n",
      "{'binary_logloss-mean': [0.06183611086548137], 'binary_logloss-stdv': [0.0011879112190564317], 'f1-mean': [0.5816068041568424], 'f1-stdv': [0.012890316312637306]}\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5816  \u001b[0m | \u001b[0m 0.7355  \u001b[0m | \u001b[0m 0.892   \u001b[0m | \u001b[0m 2.29    \u001b[0m |\n",
      "{'binary_logloss-mean': [0.10298619872798928, 0.11463427581814398, 0.0993947955034538, 0.09290089721026183, 0.09027801581580888, 0.0880602708952877, 0.08764645900881143, 0.08753424261604432, 0.08710563314256123, 0.08759426003850915, 0.0869211096704504, 0.08690714258300501], 'binary_logloss-stdv': [0.002322817079806485, 0.018714867219334165, 0.008098967317425576, 0.007243702504001509, 0.007516050847860681, 0.007378246645399298, 0.0073036020119780255, 0.006547116098961971, 0.00603830485700709, 0.005678454819862326, 0.005977618311373944, 0.005530021669387803], 'f1-mean': [0.5171647962108203, 0.49609033309909056, 0.5273672350517862, 0.5308174386899176, 0.5419329052370551, 0.5458025602322919, 0.547320088605608, 0.5584041235924657, 0.5625570901915502, 0.5666955835114054, 0.5711260624403395, 0.5761416582125284], 'f1-stdv': [0.0179049338279513, 0.033848550247015885, 0.013311684080896488, 0.01576092421753736, 0.016677316718964566, 0.01670250484522722, 0.012875153032475993, 0.007122998527309413, 0.005839336943835241, 0.006080890644769981, 0.006922006489805759, 0.007441240710921908]}\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5761  \u001b[0m | \u001b[0m 0.9834  \u001b[0m | \u001b[0m 0.8566  \u001b[0m | \u001b[0m 4.732   \u001b[0m |\n",
      "{'binary_logloss-mean': [0.046959428566126615], 'binary_logloss-stdv': [0.0010292194326707981], 'f1-mean': [0.6189586731340393], 'f1-stdv': [0.011290166054212597]}\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.619   \u001b[0m | \u001b[95m 0.7     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.047483078875506936, 0.04832262382491962, 0.04630235336658861, 0.044635574654205055], 'binary_logloss-stdv': [0.000928091753384175, 0.003596941539421231, 0.002326229045020134, 0.0021130508379543405], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.6318  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.7     \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.046959428566126615], 'binary_logloss-stdv': [0.0010292194326708007], 'f1-mean': [0.6189586731340393], 'f1-stdv': [0.011290166054212597]}\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.619   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.04748307887550693, 0.04832262382491962, 0.04630235336658861, 0.044635574654205055], 'binary_logloss-stdv': [0.000928091753384167, 0.0035969415394212297, 0.002326229045020138, 0.002113050837954339], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.047483083169985736, 0.04832262795998211, 0.04630235749269768, 0.04463828609737839], 'binary_logloss-stdv': [0.0009280908910294038, 0.0035969421269298977, 0.0023262289917638673, 0.0021096235130603188], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.047483079968242116, 0.04832262477407578, 0.04630235451144693, 0.04463557598976795], 'binary_logloss-stdv': [0.0009280914031589568, 0.003596941876555796, 0.0023262291041351883, 0.0021130510344311185], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.04748308045226721, 0.04832262511415071, 0.04630235483153983, 0.044635576346084435], 'binary_logloss-stdv': [0.0009280912843939654, 0.0035969419487628103, 0.0023262290420368687, 0.002113050992341482], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.047483080210252535, 0.0483226249021617, 0.04630235460690184, 0.04463828291257284], 'binary_logloss-stdv': [0.0009280913437829639, 0.003596941913079947, 0.0023262291183150136, 0.0021096237282232713], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.04748307887550693, 0.04832262382491963, 0.04630235336658861, 0.044635574654205055], 'binary_logloss-stdv': [0.0009280917533841697, 0.003596941539421232, 0.0023262290450201417, 0.0021130508379543396], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.8895  \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.04748308812142904, 0.048322633206048675, 0.04630236234345307, 0.04463829135129586], 'binary_logloss-stdv': [0.0009280902230758937, 0.0035969424423233586, 0.0023262289550626805, 0.002109623222039761], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.04748307923531769, 0.04832262357150966, 0.04630235363632651, 0.04463828192139493], 'binary_logloss-stdv': [0.0009280911691432485, 0.0035969421724274956, 0.002326229105130114, 0.0021096239158464453], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'binary_logloss-mean': [0.047483078875506936, 0.04832262382491963, 0.046302353366588604, 0.044635574654205055], 'binary_logloss-stdv': [0.00092809175338417, 0.003596941539421229, 0.0023262290450201378, 0.002113050837954337], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.047483079117517306, 0.04832262395993847, 0.04630235349026526, 0.044635574777946836], 'binary_logloss-stdv': [0.0009280916939960013, 0.0035969415802208156, 0.0023262290224775033, 0.0021130507489797667], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.04748307947733372, 0.04832262376919044, 0.046302353831952026, 0.04463557536081783], 'binary_logloss-stdv': [0.0009280911097530973, 0.003596942200312017, 0.0023262290976317026, 0.0021130512697044384], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 0.8508  \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'binary_logloss-mean': [0.047483092464156655, 0.04832263779562459, 0.04630236638723378, 0.04463829571690684], 'binary_logloss-stdv': [0.0009280897865660305, 0.003596942473383632, 0.0023262288768549273, 0.002109622639058645], 'f1-mean': [0.5866811471589426, 0.614284892278231, 0.6260123935082563, 0.6318176563319053], 'f1-stdv': [0.013887586143881787, 0.02466391515127404, 0.017964742226144616, 0.01782062692435651]}\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6318  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1_score(y_pred, y_true):\n",
    "    \"\"\"evaluation metric\"\"\"\n",
    "    #print (\"y_pred\",y_pred)\n",
    "    #print (\"y_true\",y_true)\n",
    "    y_hat = np.round(y_pred)\n",
    "    return 'f1', f1_score(y_true.get_label(), y_hat), True\n",
    "\n",
    "def bayes_parameter_opt_lgb(X, y, \n",
    "                            init_round=15, \n",
    "                            opt_round=25, \n",
    "                            n_folds=5, \n",
    "                            random_seed=1030,\n",
    "                            n_estimators=10000,\n",
    "                            learning_rate=0.05, \n",
    "                            output_process=True):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, categorical_feature='auto', free_raw_data = False)\n",
    "    # parameters\n",
    "    def lgb_eval(\n",
    "        #num_leaves, \n",
    "        feature_fraction, bagging_fraction,\n",
    "                 #max_depth, \n",
    "                 #lambda_l1, lambda_l2, min_split_gain, \n",
    "                 #min_child_weight, max_bin, \n",
    "                 scale_pos_weight):\n",
    "        params = {'application':'binary',\n",
    "                  'num_iterations': n_estimators, \n",
    "                  'learning_rate':learning_rate, \n",
    "                  'early_stopping_round':100, \n",
    "                  'n_jobs':-1,\n",
    "                  }\n",
    "#         params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        #params['max_depth'] = int(round(max_depth))\n",
    "#         params['lambda_l1'] = max(lambda_l1, 0)\n",
    "#         params['lambda_l2'] = max(lambda_l2, 0)\n",
    "#         params['min_split_gain'] = min_split_gain\n",
    "#         params['min_child_weight'] = min_child_weight\n",
    "#         params['max_bin'] = int(round(max_bin))\n",
    "        params['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "        cv_result = lgb.cv(params, \n",
    "                           train_data, \n",
    "                           nfold=n_folds,\n",
    "                           seed=random_seed, \n",
    "                           stratified=True, \n",
    "                           categorical_feature = \"auto\",\n",
    "                           feval=lgb_f1_score)\n",
    "        print (cv_result)\n",
    "        return max(cv_result['f1-mean'])\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {\n",
    "#         'num_leaves': (24, 45),\n",
    "                                            'feature_fraction': (0.7, 1.0),\n",
    "                                            'bagging_fraction': (0.7, 1.0),\n",
    "#                                             'lambda_l1': (0, 5),\n",
    "#                                             'lambda_l2': (0, 3),\n",
    "#                                             'min_split_gain': (0.0, 0.1),\n",
    "#                                             'min_child_weight': (1, 50),\n",
    "                                            'scale_pos_weight': (1, 10),\n",
    "#                                             'max_bin': (255,355),\n",
    "                                           }, \n",
    "                                 random_state=0)\n",
    "    # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    # output optimization process\n",
    "    if output_process==True: \n",
    "        pd.DataFrame(lgbBO.res).sort_values(by = \"target\", ascending=False).to_csv(\"../fraud_detection/result/bayes_opt_result.csv\")\n",
    "    return lgbBO.max[\"target\"], lgbBO.max[\"params\"] # best score and best parameter\n",
    "#     return lgbBO\n",
    "#     # return best parameters\n",
    "#     return lgbBO.res['max']['max_params']\n",
    "\n",
    "opt_score, opt_params = bayes_parameter_opt_lgb(X, y, \n",
    "                                     init_round=10, \n",
    "                                     opt_round=15, \n",
    "                                     n_folds=5, \n",
    "                                     random_seed=1030, \n",
    "                                     n_estimators=10000, \n",
    "                                     learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.9999999999997958,\n",
       " 'feature_fraction': 0.7,\n",
       " 'scale_pos_weight': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6318176563319053"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params.max[\"target\"], opt_params.max[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "pd.DataFrame(opt_params.res).sort_values(by = \"target\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\":[1,2,3,4],\"B\":[1,1,1,1]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"] = df[\"A\"].copy().sample(frac = 1.0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.A.copy().sample(frac = 1.0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(\n",
    "    n_jobs = 3,\n",
    "    boosting_type = \"rf\",\n",
    "    # nthread=int(multiprocessing.cpu_count()*args.CPU_USE_RATE),\n",
    "    n_estimators=10000,\n",
    "    )\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(lgb.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
