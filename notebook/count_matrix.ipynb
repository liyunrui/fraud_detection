{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_columns = 300\n",
    "import sys\n",
    "sys.path.append(\"../fraud_detection/src/\")\n",
    "from util import s_to_time_format, string_to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"../dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def value_to_count(df_train, df_test):\n",
    "\n",
    "    # continuous_feats = [\"locdt\",\"conam\",\"loctm_hour_of_day\",\n",
    "    #                 \"loctm_minute_of_hour\",\"loctm_second_of_min\"]\n",
    "\n",
    "    # feats = [f for f in df_test.columns.tolist() if f not in continuous_feats]\n",
    "    feats = ['acqic', 'bacno', 'cano', 'conam', 'contp', 'csmcu', 'ecfg', 'etymd',\n",
    "       'flbmk', 'flg_3dsmk', 'hcefg', 'insfg', 'iterm', 'mcc',\n",
    "       'mchno', 'ovrlt', 'scity', 'stocn', 'stscd']\n",
    "\n",
    "    df = pd.concat([df_train[feats], df_test[feats]], axis = 0)\n",
    "    df_train_ = pd.DataFrame()\n",
    "    df_test_ = pd.DataFrame()\n",
    "    for f in tqdm(feats):\n",
    "        count_dict = df[f].value_counts(dropna = False).to_dict() \n",
    "        df_train_[f] = df_train[f].apply(lambda v: count_dict[v])\n",
    "        df_test_[f] = df_test[f].apply(lambda v: count_dict[v])\n",
    "    continuous_feats = ['locdt', 'loctm_hour_of_day', 'loctm_minute_of_hour', 'loctm_second_of_min']\n",
    "    for f in tqdm(continuous_feats):\n",
    "        df_train_[f] = df_train[f]\n",
    "        df_test_[f] = df_test[f]\n",
    "    df_train_[\"fraud_ind\"] = df_train[\"fraud_ind\"]\n",
    "    \n",
    "    return df_train_, df_test_\n",
    "\n",
    "def feature_normalization_auto(df_train, df_test, mode = \"train\"):\n",
    "    \"\"\"\n",
    "    return two inputs of autoencoder, one is for train and another one is for test\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "    feats = ['acqic', 'bacno', 'cano', 'conam', 'contp', 'csmcu', 'ecfg', 'etymd',\n",
    "       'flbmk', 'flg_3dsmk', 'hcefg', 'insfg', 'iterm', 'locdt', 'mcc',\n",
    "       'mchno', 'ovrlt', 'scity', 'stocn', 'stscd', 'loctm_hour_of_day',\n",
    "       'loctm_minute_of_hour', 'loctm_second_of_min']\n",
    "    scaler = MinMaxScaler()\n",
    "    df = pd.concat([df_train[feats], df_test[feats]], axis = 0)\n",
    "\n",
    "    data = df[feats]\n",
    "    scaler.fit(data)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        X_train = df_train[df_train.fraud_ind == 0]\n",
    "        \n",
    "        X_train = X_train[feats]\n",
    "        X_test = df_test[feats]\n",
    "        \n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    else:\n",
    "        X_train = scaler.transform(df_train[feats])\n",
    "        X_test = scaler.transform(df_test[feats])\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:15<00:00,  1.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 133.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    # pre-processing\n",
    "    df[\"loctm_\"] = df.loctm.astype(int).astype(str)\n",
    "    df.loctm_ = df.loctm_.apply(s_to_time_format).apply(string_to_datetime)\n",
    "    # time-related feature\n",
    "    df[\"loctm_hour_of_day\"] = df.loctm_.apply(lambda x: x.hour).astype('category')\n",
    "    df[\"loctm_minute_of_hour\"] = df.loctm_.apply(lambda x: x.minute)\n",
    "    df[\"loctm_second_of_min\"] = df.loctm_.apply(lambda x: x.second)\n",
    "    \n",
    "df_train_, df_test_ = value_to_count(df_train, df_test)\n",
    "\n",
    "\n",
    "X_train, X_test = feature_normalization_auto(df_train_, df_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acqic</th>\n",
       "      <th>bacno</th>\n",
       "      <th>cano</th>\n",
       "      <th>conam</th>\n",
       "      <th>contp</th>\n",
       "      <th>csmcu</th>\n",
       "      <th>ecfg</th>\n",
       "      <th>etymd</th>\n",
       "      <th>flbmk</th>\n",
       "      <th>flg_3dsmk</th>\n",
       "      <th>fraud_ind</th>\n",
       "      <th>hcefg</th>\n",
       "      <th>insfg</th>\n",
       "      <th>iterm</th>\n",
       "      <th>locdt</th>\n",
       "      <th>loctm</th>\n",
       "      <th>mcc</th>\n",
       "      <th>mchno</th>\n",
       "      <th>ovrlt</th>\n",
       "      <th>scity</th>\n",
       "      <th>stocn</th>\n",
       "      <th>stscd</th>\n",
       "      <th>txkey</th>\n",
       "      <th>loctm_</th>\n",
       "      <th>loctm_hour_of_day</th>\n",
       "      <th>loctm_minute_of_hour</th>\n",
       "      <th>loctm_second_of_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6881</td>\n",
       "      <td>113261</td>\n",
       "      <td>38038</td>\n",
       "      <td>513.80</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>172652.0</td>\n",
       "      <td>457</td>\n",
       "      <td>59333</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>516056</td>\n",
       "      <td>1900-01-01 17:26:52</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134508</td>\n",
       "      <td>45725</td>\n",
       "      <td>465.62</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>105114.0</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5817</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>4376</td>\n",
       "      <td>1900-01-01 10:51:14</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6881</td>\n",
       "      <td>15408</td>\n",
       "      <td>188328</td>\n",
       "      <td>513.80</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>152458.0</td>\n",
       "      <td>457</td>\n",
       "      <td>59333</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>483434</td>\n",
       "      <td>1900-01-01 15:24:58</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6716</td>\n",
       "      <td>157159</td>\n",
       "      <td>29967</td>\n",
       "      <td>1016.11</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172946.0</td>\n",
       "      <td>247</td>\n",
       "      <td>50436</td>\n",
       "      <td>N</td>\n",
       "      <td>3281</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1407164</td>\n",
       "      <td>1900-01-01 17:29:46</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5975</td>\n",
       "      <td>105985</td>\n",
       "      <td>81305</td>\n",
       "      <td>713.66</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>182129.0</td>\n",
       "      <td>263</td>\n",
       "      <td>93775</td>\n",
       "      <td>N</td>\n",
       "      <td>5817</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1051004</td>\n",
       "      <td>1900-01-01 18:21:29</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acqic   bacno    cano    conam  contp  csmcu ecfg  etymd flbmk flg_3dsmk  \\\n",
       "0   6881  113261   38038   513.80      5      0    N      0     N         N   \n",
       "1      0  134508   45725   465.62      5      0    N      2     N         N   \n",
       "2   6881   15408  188328   513.80      5      0    N      0     N         N   \n",
       "3   6716  157159   29967  1016.11      5     62    N      5     N         N   \n",
       "4   5975  105985   81305   713.66      5     62    N      4     N         N   \n",
       "\n",
       "   fraud_ind  hcefg insfg  iterm  locdt     loctm  mcc  mchno ovrlt  scity  \\\n",
       "0          0      5     N      0     33  172652.0  457  59333     N      0   \n",
       "1          0      0     N      0      9  105114.0  451      0     N   5817   \n",
       "2          0      5     N      0      6  152458.0  457  59333     N      0   \n",
       "3          0      5     N      0      5  172946.0  247  50436     N   3281   \n",
       "4          0      5     N      0      6  182129.0  263  93775     N   5817   \n",
       "\n",
       "   stocn  stscd    txkey              loctm_ loctm_hour_of_day  \\\n",
       "0    102      0   516056 1900-01-01 17:26:52                17   \n",
       "1    102      0     4376 1900-01-01 10:51:14                10   \n",
       "2    102      0   483434 1900-01-01 15:24:58                15   \n",
       "3    102      0  1407164 1900-01-01 17:29:46                17   \n",
       "4    102      0  1051004 1900-01-01 18:21:29                18   \n",
       "\n",
       "   loctm_minute_of_hour  loctm_second_of_min  \n",
       "0                    26                   52  \n",
       "1                    51                   14  \n",
       "2                    24                   58  \n",
       "3                    29                   46  \n",
       "4                    21                   29  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1501432, 23)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39383468, 0.07078853, 0.07078853, 1.        , 1.        ,\n",
       "       0.14213743, 1.        , 0.32460156, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.26890756, 0.53854708,\n",
       "       0.64663047, 1.        , 0.19615079, 1.        , 1.        ,\n",
       "       0.73913043, 0.44067797, 0.88135593])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39383468, 0.00896057, 0.00896057, 1.        , 1.        ,\n",
       "       0.14213743, 1.        , 0.32460156, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.8487395 , 0.53854708,\n",
       "       0.08129571, 1.        , 0.19615079, 1.        , 1.        ,\n",
       "       0.91304348, 0.89830508, 0.47457627])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1501432, 23), (421665, 23))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras import regularizers\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "def autoencoder(input_dim, encoding_dim):\n",
    "    \"\"\"\n",
    "    architecture of autoencoder, we consider this as a dimension reduction method. \n",
    "    encoding_dim: int\n",
    "    input_dim: int.\n",
    "    \"\"\"\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.models import Model\n",
    "    \n",
    "    input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "    encoder = Dense(encoding_dim, activation=\"tanh\",\n",
    "                    activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "    encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "\n",
    "    decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "    decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "def build_model(autoencoder,X_train,X_test,nb_epoch = 100,batch_size = 32):\n",
    "    \"\"\"\n",
    "    X_train: data only including normal transation data\n",
    "\n",
    "    X_test: data both including fradulant and normal data \n",
    "    \"\"\"\n",
    "    autoencoder.compile(optimizer='adam',\n",
    "                        loss='mean_squared_error',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=\"../fraud_detection/models/auto_encoder.h5\",\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', \n",
    "                                  min_delta=0, \n",
    "                                  patience=5, \n",
    "                                  verbose=1, \n",
    "                                  mode='auto', \n",
    "                                  baseline=None, \n",
    "                                  restore_best_weights=False)\n",
    "\n",
    "#     tensorboard = TensorBoard(log_dir='/media/old-tf-hackers-7/logs',\n",
    "#                               histogram_freq=0,\n",
    "#                               write_graph=True,\n",
    "#                               write_images=True)\n",
    "    history = autoencoder.fit(X_train, X_train,\n",
    "                        epochs=nb_epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_test, X_test),\n",
    "                        verbose=1,\n",
    "                        callbacks=[checkpointer, earlystopper]).history\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of raw features 23\n",
      "number of normal data 1501432\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14)                336       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 105       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 23)                184       \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1501432 samples, validate on 421665 samples\n",
      "Epoch 1/100\n",
      "1501432/1501432 [==============================] - 160s 107us/step - loss: 0.0263 - acc: 0.1259 - val_loss: 0.0269 - val_acc: 0.1758\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02688, saving model to ../fraud_detection/models/auto_encoder.h5\n",
      "Epoch 2/100\n",
      "1501432/1501432 [==============================] - 157s 104us/step - loss: 0.0171 - acc: 0.1320 - val_loss: 0.0253 - val_acc: 0.1641\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02688 to 0.02535, saving model to ../fraud_detection/models/auto_encoder.h5\n",
      "Epoch 3/100\n",
      "1501432/1501432 [==============================] - 157s 105us/step - loss: 0.0164 - acc: 0.1462 - val_loss: 0.0255 - val_acc: 0.1307\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02535\n",
      "Epoch 4/100\n",
      "1501432/1501432 [==============================] - 154s 103us/step - loss: 0.0162 - acc: 0.1237 - val_loss: 0.0254 - val_acc: 0.0578\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02535\n",
      "Epoch 5/100\n",
      "1501432/1501432 [==============================] - 161s 108us/step - loss: 0.0161 - acc: 0.1118 - val_loss: 0.0250 - val_acc: 0.1383\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02535 to 0.02498, saving model to ../fraud_detection/models/auto_encoder.h5\n",
      "Epoch 6/100\n",
      "1501432/1501432 [==============================] - 158s 105us/step - loss: 0.0161 - acc: 0.1098 - val_loss: 0.0255 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02498\n",
      "Epoch 7/100\n",
      "1501432/1501432 [==============================] - 158s 105us/step - loss: 0.0161 - acc: 0.1080 - val_loss: 0.0250 - val_acc: 0.0558\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02498\n",
      "Epoch 8/100\n",
      "1501432/1501432 [==============================] - 158s 105us/step - loss: 0.0160 - acc: 0.1066 - val_loss: 0.0250 - val_acc: 0.0434\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02498 to 0.02497, saving model to ../fraud_detection/models/auto_encoder.h5\n",
      "Epoch 9/100\n",
      "1501432/1501432 [==============================] - 158s 105us/step - loss: 0.0160 - acc: 0.1074 - val_loss: 0.0253 - val_acc: 0.0506\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02497\n",
      "Epoch 10/100\n",
      "1501432/1501432 [==============================] - 158s 105us/step - loss: 0.0160 - acc: 0.1075 - val_loss: 0.0253 - val_acc: 0.1042\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02497\n",
      "Epoch 11/100\n",
      "1501432/1501432 [==============================] - 156s 104us/step - loss: 0.0160 - acc: 0.1073 - val_loss: 0.0249 - val_acc: 0.1527\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02497 to 0.02486, saving model to ../fraud_detection/models/auto_encoder.h5\n",
      "Epoch 12/100\n",
      "1501432/1501432 [==============================] - 159s 106us/step - loss: 0.0159 - acc: 0.1070 - val_loss: 0.0247 - val_acc: 0.0903\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02486 to 0.02472, saving model to ../fraud_detection/models/auto_encoder.h5\n",
      "Epoch 13/100\n",
      "1501432/1501432 [==============================] - 159s 106us/step - loss: 0.0159 - acc: 0.1079 - val_loss: 0.0256 - val_acc: 0.1619\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02472\n",
      "Epoch 14/100\n",
      "1501432/1501432 [==============================] - 157s 105us/step - loss: 0.0159 - acc: 0.1083 - val_loss: 0.0249 - val_acc: 0.1410\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02472\n",
      "Epoch 15/100\n",
      "1501432/1501432 [==============================] - 158s 105us/step - loss: 0.0159 - acc: 0.1084 - val_loss: 0.0253 - val_acc: 0.0721\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02472\n",
      "Epoch 16/100\n",
      "1501432/1501432 [==============================] - 159s 106us/step - loss: 0.0159 - acc: 0.1083 - val_loss: 0.0250 - val_acc: 0.1533\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02472\n",
      "Epoch 17/100\n",
      "1501432/1501432 [==============================] - 157s 105us/step - loss: 0.0159 - acc: 0.1087 - val_loss: 0.0254 - val_acc: 0.0980\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02472\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 14\n",
    "print ('number of raw features', input_dim)\n",
    "print ('number of normal data', X_train.shape[0])\n",
    "\n",
    "\n",
    "autoencoder = autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "print (autoencoder.summary())\n",
    "\n",
    "history = build_model(autoencoder,X_train,X_test,nb_epoch = 100,batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.026882006505459702,\n",
       "  0.02534960339153805,\n",
       "  0.02553966923554332,\n",
       "  0.02539221179169851,\n",
       "  0.024983544004278976,\n",
       "  0.025507344490536318,\n",
       "  0.025030158581719166,\n",
       "  0.024971744224800894,\n",
       "  0.025317067245280475,\n",
       "  0.02530462072098653,\n",
       "  0.024856984690478433,\n",
       "  0.024723459454908742,\n",
       "  0.025576533185929895,\n",
       "  0.02485913510730392,\n",
       "  0.025314931449591044,\n",
       "  0.02503664812353106,\n",
       "  0.025378806135601704],\n",
       " 'val_acc': [0.17576749315214685,\n",
       "  0.16414926541211625,\n",
       "  0.13066533859817628,\n",
       "  0.05782078190032372,\n",
       "  0.13830647551966607,\n",
       "  0.12108901616211921,\n",
       "  0.05580733520685852,\n",
       "  0.043418353432227004,\n",
       "  0.05063735429784307,\n",
       "  0.10421780323242384,\n",
       "  0.15265672986849751,\n",
       "  0.09033000130435298,\n",
       "  0.16189629208020584,\n",
       "  0.14100530041620718,\n",
       "  0.07213546298601971,\n",
       "  0.15327570464705395,\n",
       "  0.09797588132759417],\n",
       " 'loss': [0.02626731877726906,\n",
       "  0.017115127253145443,\n",
       "  0.016373479083622154,\n",
       "  0.016209797632336227,\n",
       "  0.01614833804999057,\n",
       "  0.016103980597582505,\n",
       "  0.016077539993226135,\n",
       "  0.016031960081146615,\n",
       "  0.01599171477198164,\n",
       "  0.015972057859537477,\n",
       "  0.015956820094211586,\n",
       "  0.01594709922268078,\n",
       "  0.015933887968423058,\n",
       "  0.015927978784473298,\n",
       "  0.015917822055550625,\n",
       "  0.015915444781080323,\n",
       "  0.015916559283723025],\n",
       " 'acc': [0.12589447940374204,\n",
       "  0.13200864241606,\n",
       "  0.14621174984947705,\n",
       "  0.12372455096205463,\n",
       "  0.11178261819387066,\n",
       "  0.10978186158284864,\n",
       "  0.10797891612808959,\n",
       "  0.10662221132893784,\n",
       "  0.10742078229319063,\n",
       "  0.10751003042428828,\n",
       "  0.10728557803487578,\n",
       "  0.10703381838142494,\n",
       "  0.10787301722622136,\n",
       "  0.10826597541547003,\n",
       "  0.10839252127304454,\n",
       "  0.10828728840204525,\n",
       "  0.10870022751613127]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
