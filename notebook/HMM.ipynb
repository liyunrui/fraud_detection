{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded completely.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "\n",
    "class Driver:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self._data = np.array(pandas.read_csv(filepath_or_buffer=path, sep=' ', header=None)).flatten()\n",
    "        print('Dataset loaded completely.')\n",
    "\n",
    "    def get_data(self):\n",
    "        return self._data\n",
    "\n",
    "    def generate_test_data(self, sample):\n",
    "        return np.concatenate((self._data[1:], [sample])) \n",
    "d = Driver('../Credit-Card-Fraud-Detection/Data/train_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.generate_test_data(5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering as Linkage\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# Kmeans clustering algorithm\n",
    "class KMeansClustering:\n",
    "    def __init__(self, n_clusters=3):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.__model = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "\n",
    "    def run(self, data):\n",
    "        print('Clustering ...')\n",
    "        data = np.array([[x] for x in data])\n",
    "        print('Clustering is finished.')\n",
    "        return self.__model.fit(X=data).labels_\n",
    "\n",
    "    def predict(self, sample):\n",
    "        return self.__model.predict(X=[[sample]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KMeansClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering ...\n",
      "Clustering is finished.\n"
     ]
    }
   ],
   "source": [
    "observations = k.run(d.get_data()[0:192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hidden_markov import hmm\n",
    "\n",
    "\n",
    "# Divide function\n",
    "def divide(num, denom):\n",
    "    if num == 0:\n",
    "        return 0\n",
    "\n",
    "    return num / denom\n",
    "\n",
    "\n",
    "# Hidden Markov Model\n",
    "class HMM:\n",
    "    def __init__(self, n_states, n_possible_observations):\n",
    "        # Number of states\n",
    "        self.n_states = n_states\n",
    "        # Number of possible observations\n",
    "        self.n_possible_observations = n_possible_observations\n",
    "        # Create states and possible observations\n",
    "        self.states, self.possible_observations = self.__init_names()\n",
    "        # Create transition matrix, emission matrix and start probability matrix\n",
    "        self.pi_prob, self.transition_prob, self.emission_prob = self.__init_probabilities()\n",
    "\n",
    "        # Create model\n",
    "        self.__model = hmm(states=list(self.states),\n",
    "                           observations=list(self.possible_observations),\n",
    "                           start_prob=np.matrix(self.pi_prob),\n",
    "                           trans_prob=np.matrix(self.transition_prob),\n",
    "                           em_prob=np.matrix(self.emission_prob))\n",
    "\n",
    "    # Initialize states and possible observations\n",
    "    def __init_names(self):\n",
    "        states = np.array(range(self.n_states))\n",
    "        possible_observations = np.array(range(self.n_possible_observations))\n",
    "        return states, possible_observations\n",
    "\n",
    "    # Initialize probability of transition matrix and emission matrix\n",
    "    def __init_probabilities(self):\n",
    "        pi_prob = np.zeros(self.n_states)\n",
    "        transition_prob = np.zeros((self.n_states, self.n_states))\n",
    "        emission_prob = np.zeros((self.n_states, self.n_possible_observations))\n",
    "\n",
    "        for i in range(self.n_states):\n",
    "            pi_prob[i] = 1 / self.n_states\n",
    "\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(self.n_states):\n",
    "                transition_prob[i][j] = 1 / self.n_states\n",
    "\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(self.n_possible_observations):\n",
    "                emission_prob[i][j] = 1 / self.n_possible_observations\n",
    "\n",
    "        return pi_prob, transition_prob, emission_prob\n",
    "\n",
    "    # Implement the Baum-Welch Algorithm for HMM\n",
    "    def train_model(self, observations, steps):\n",
    "        print('HMM is training ...')\n",
    "        pi_prob = np.zeros(self.n_states)\n",
    "        transition_prob = np.zeros((self.n_states, self.n_states))\n",
    "        emission_prob = np.zeros((self.n_states, self.n_possible_observations))\n",
    "\n",
    "        # Main loop for given steps\n",
    "        for _ in range(steps):\n",
    "            # Calculation of Forward-Backward variables from the current observations\n",
    "            fwd = self.forward_process(observations)\n",
    "            bwd = self.backward_process(observations)\n",
    "\n",
    "            # Re-estimating of initial state probabilities\n",
    "            for i in range(self.n_states):\n",
    "                pi_prob[i] = self.calculate_gamma(i, 0, fwd, bwd)\n",
    "\n",
    "            # Re-estimating of transition probabilities\n",
    "            for i in range(self.n_states):\n",
    "                for j in range(self.n_states):\n",
    "                    num, denom = 0, 0\n",
    "                    for t in range(len(observations)):\n",
    "                        num += self.calculate_path_probability(t, i, j, observations, fwd, bwd)\n",
    "                        denom += self.calculate_gamma(i, t, fwd, bwd)\n",
    "\n",
    "                    transition_prob[i][j] = divide(num, denom)\n",
    "\n",
    "            # Re-estimating of emission probabilities\n",
    "            for i in range(self.n_states):\n",
    "                for k in range(self.n_possible_observations):\n",
    "                    num, denom = 0, 0\n",
    "                    for t in range(len(observations)):\n",
    "                        g = self.calculate_gamma(i, t, fwd, bwd)\n",
    "                        if k == observations[t]:\n",
    "                            num += g\n",
    "                        denom += g\n",
    "\n",
    "                    emission_prob[i][k] = divide(num, denom)\n",
    "\n",
    "        self.pi_prob = pi_prob\n",
    "        self.transition_prob = transition_prob\n",
    "        self.emission_prob = emission_prob\n",
    "        print('HMM has successfully trained.')\n",
    "\n",
    "    # Forward algorithm\n",
    "    # Calculate Forward-Variables fwd[i][t] for state i at time t for current observations\n",
    "    def forward_process(self, observations):\n",
    "        fwd = np.zeros((self.n_states, len(observations)))\n",
    "        # Initialization at time = 0\n",
    "        for i in range(self.n_states):\n",
    "            fwd[i][0] = self.pi_prob[i] * self.emission_prob[i][observations[0]]\n",
    "\n",
    "        # Induction\n",
    "        for t in range(len(observations) - 1):\n",
    "            for j in range(self.n_states):\n",
    "                fwd[j][t + 1] = 0\n",
    "                for i in range(self.n_states):\n",
    "                    fwd[j][t + 1] += (fwd[i][t] * self.transition_prob[i][j])\n",
    "\n",
    "                fwd[j][t + 1] = (fwd[j][t + 1] * self.emission_prob[j][observations[t + 1]])\n",
    "\n",
    "        return fwd\n",
    "\n",
    "    # Backward algorithm\n",
    "    # Calculate Backward-Variables bwd[i][t] for state i at time t for current observations\n",
    "    def backward_process(self, observations):\n",
    "        bwd = np.zeros((self.n_states, len(observations)))\n",
    "        # Initialization at time = 0\n",
    "        for i in range(self.n_states):\n",
    "            bwd[i][len(observations) - 1] = 1\n",
    "\n",
    "        # Induction\n",
    "        for t in range(len(observations) - 2, -1, -1):\n",
    "            for i in range(self.n_states):\n",
    "                bwd[i][t] = 0\n",
    "                for j in range(self.n_states):\n",
    "                    bwd[i][t] += (\n",
    "                            bwd[j][t + 1] * self.transition_prob[i][j] * self.emission_prob[j][observations[t + 1]])\n",
    "\n",
    "        return bwd\n",
    "\n",
    "    # Calculate gamma[i][t]; expected count\n",
    "    def calculate_gamma(self, cur_state, t, fwd, bwd):\n",
    "        num = fwd[cur_state][t] * bwd[cur_state][t]\n",
    "        denom = 0\n",
    "        for i in range(self.n_states):\n",
    "            denom += (fwd[i][t] * bwd[i][t])\n",
    "\n",
    "        return divide(num, denom)\n",
    "\n",
    "    # Calculate the probability of P(x_t = s_i, x_t+1 = s_j | observations).\n",
    "    # t = current time\n",
    "    # x_t = current state\n",
    "    # x_t+1 = next state\n",
    "    # s_i = i'th state\n",
    "    # s_j = j'th state\n",
    "    def calculate_path_probability(self, t, i, j, observations, fwd, bwd):\n",
    "        num, denom = 0, 0\n",
    "        if t == len(observations) - 1:\n",
    "            num = fwd[i][t] * self.transition_prob[i][j]\n",
    "        else:\n",
    "            num = fwd[i][t] * self.transition_prob[i][j] * self.emission_prob[j][observations[t + 1]] * bwd[j][t + 1]\n",
    "\n",
    "        for k in range(self.n_states):\n",
    "            denom += (fwd[k][t] * bwd[k][t])\n",
    "\n",
    "        return divide(num, denom)\n",
    "\n",
    "    # Calculate the probability of the occurrence of specific observation\n",
    "    def calculate_occurrence_probability(self, observations):\n",
    "        fwd = self.forward_process(observations)\n",
    "        bwd = self.backward_process(observations)\n",
    "        result = np.zeros(len(observations))\n",
    "\n",
    "        for i in range(len(observations)):\n",
    "            for j in range(self.n_states):\n",
    "                result[i] += fwd[j][i] * bwd[j][i]\n",
    "\n",
    "        return result\n",
    "\n",
    "    # Detect fraud\n",
    "    def detect_fraud(self, observations, new_observation, threshold):\n",
    "        print('Fraud evaluation ...')\n",
    "        alpha_1 = self.calculate_occurrence_probability(observations)\n",
    "        alpha_2 = self.calculate_occurrence_probability(new_observation)\n",
    "        delta = alpha_1[0] - alpha_2[0]\n",
    "        delta = delta / alpha_1[0]\n",
    "\n",
    "        if delta > threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "THRESHOLD = 0.9\n",
    "STATES = 5\n",
    "CLUSTERS = 3\n",
    "STEPS = 200\n",
    "TEST_RANGE = 1000\n",
    "TERMINATE = -1\n",
    "\n",
    "h = HMM(n_states=STATES, n_possible_observations=CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM is training ...\n",
      "HMM has successfully trained.\n"
     ]
    }
   ],
   "source": [
    "h.train_model(observations=list(observations), steps=STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
