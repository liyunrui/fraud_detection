{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Build model...')\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, 128, name = \"main_input\"))\n",
    "# model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2,name='lstm_output'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Embedding, LSTM, Dense, merge\n",
    "# from keras.models import Model\n",
    "\n",
    "# # headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# # note that we can name any layer by passing it a \"name\" argument.\n",
    "# main_input = Input(shape=(80,), dtype='int32', name='main_input')\n",
    "# print (main_input)\n",
    "# # this embedding layer will encode the input sequence\n",
    "# # into a sequence of dense 512-dimensional vectors.\n",
    "# x = Embedding(output_dim=128, input_dim=20000, input_length=80)(main_input)\n",
    "# print (x)\n",
    "# # a LSTM will transform the vector sequence into a single vector,\n",
    "# # containing information about the entire sequence\n",
    "# lstm_out = LSTM(32,return_sequences = True)(x)\n",
    "# print (lstm_out)\n",
    "\n",
    "# auxiliary_loss = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "# print (auxiliary_loss)\n",
    "\n",
    "# # auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "# # x = merge([lstm_out, auxiliary_input], mode='concat')\n",
    "\n",
    "# # we stack a deep fully-connected network on top\n",
    "# x = Dense(64, activation='relu', name=\"dense_one\")(x) # names are added here\n",
    "# x = Dense(64, activation='relu', name=\"dense_two\")(x)\n",
    "# x = Dense(64, activation='relu', name=\"dense_three\")(x)\n",
    "# print (x)\n",
    "\n",
    "# # and finally we add the main logistic regression layer\n",
    "# main_loss = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "# print (main_loss)\n",
    "\n",
    "# model = Model(input=[main_input], output=[main_loss])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "#               loss_weights=[1.])\n",
    "# #model.get_layer(\"dense_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try using different optimizers and different optimizer configs\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# print('Train...')\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=1,\n",
    "#           validation_data=(x_test, y_test)\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Tensor(\"embedding_70/embedding_lookup/Identity:0\", shape=(?, 100, 512), dtype=float32)\n",
      "x2 Tensor(\"embedding_71/embedding_lookup/Identity:0\", shape=(?, 100, 10), dtype=float32)\n",
      "Tensor(\"lstm_out_40/transpose_1:0\", shape=(?, ?, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "np.random.seed(0)  # Set a random seed for reproducibility\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "main_input_2 = Input(shape=(100,), dtype='int32', name='main_input_2')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "x2 = Embedding(output_dim=10, input_dim=2, input_length=100)(main_input_2)\n",
    "print (\"x\",x)\n",
    "print (\"x2\",x2)\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out,state_h,state_c = LSTM(32, name = \"lstm_out\", return_sequences = True, return_state = True)(x)\n",
    "#lstm_out_feature = LSTM(32, name = \"lstm_out_feature\", return_sequences = True)(x)\n",
    "print (lstm_out)\n",
    "#auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "#auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "#x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "#print (x)\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu',name=\"dense_one\")(state_h)\n",
    "x = Dense(64, activation='relu',name=\"dense_two\")(x)\n",
    "x = Dense(64, activation='relu',name=\"dense_three\")(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "model = Model(inputs=[main_input], outputs=[main_output])\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              loss_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_data = np.round(np.abs(np.random.rand(12, 100) * 100))\n",
    "headline_data_1 = np.round(np.abs(np.random.rand(12, 100) * 2))\n",
    "\n",
    "#additional_data = np.random.randn(12, 5)\n",
    "headline_labels = np.random.randn(12, 1)\n",
    "#additional_labels = np.random.randn(12, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 100)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 2., 1., 2., 1., 0., 1., 0., 0., 1., 1., 2., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 2., 1., 1., 0., 2., 1., 1., 0.,\n",
       "       0., 0., 2., 2., 1., 2., 0., 1., 0., 2., 1., 0., 1., 1., 2., 0., 1.,\n",
       "       2., 0., 1., 0., 2., 1., 2., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 2., 0., 1., 0., 1., 0., 0., 1., 2., 0., 2., 1., 1., 2., 1.,\n",
       "       0., 0., 0., 2., 1., 1., 2., 0., 1., 1., 1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_data_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 6s 526ms/step - loss: 0.6936 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6498 - acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5720 - acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4471 - acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2358 - acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -0.1124 - acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -0.6465 - acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: -1.3919 - acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -2.2623 - acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -3.3189 - acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: -4.5295 - acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -5.8324 - acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.1223 - acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.4428 - acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.5135 - acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: -7.5384 - acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.5685 - acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.5730 - acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.5830 - acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: -7.5990 - acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.6123 - acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.6255 - acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.6442 - acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.6624 - acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.6799 - acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.6889 - acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.7088 - acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.7365 - acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.7597 - acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.7821 - acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.8060 - acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: -7.8319 - acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.8606 - acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.8925 - acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.9272 - acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -7.9658 - acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.0040 - acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: -8.0262 - acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: -8.1015 - acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.1642 - acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.2162 - acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: -8.2506 - acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.2250 - acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.3789 - acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.4869 - acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.6210 - acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.7241 - acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.8554 - acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -8.9778 - acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -9.1253 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b95ff8828>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit([headline_data, additional_data], [headline_labels, additional_labels, ],\n",
    "#           epochs=5, batch_size=32)\n",
    "# And trained it via:\n",
    "model.fit({'main_input': headline_data, \n",
    "           'main_input_2': headline_data_1,\n",
    "          },\n",
    "          {'main_output': headline_labels, \n",
    "           #'aux_output': additional_labels\n",
    "          },\n",
    "          epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output, auxiliary_output = model.predict({'main_input': headline_data, 'aux_input': additional_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auxiliary_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [2.9802322e-08],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [7.7507401e-01],\n",
       "       [9.9517137e-01],\n",
       "       [0.0000000e+00],\n",
       "       [2.4931315e-01]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3938566e-01],\n",
       "       [1.1312962e-03],\n",
       "       [8.3271861e-03],\n",
       "       [7.5623226e-01],\n",
       "       [3.3980608e-04],\n",
       "       [2.4066001e-01],\n",
       "       [4.6593377e-01],\n",
       "       [1.4150143e-04],\n",
       "       [4.9779296e-01],\n",
       "       [2.7680397e-04],\n",
       "       [4.0855616e-01],\n",
       "       [3.7595630e-04]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auxiliary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'main_input_38:0' shape=(?, 100) dtype=int32>,\n",
       " <tf.Tensor 'aux_input_18:0' shape=(?, 5) dtype=float32>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"lstm_out\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(model.inputs, model.get_layer(\"lstm_out\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out, state_h, state_c = new_model.predict({'main_input': headline_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 100, 32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(model.inputs, model.get_layer(\"dense_three\").output)\n",
    "hidden_out = new_model.predict({'main_input': headline_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Model(model.inputs, model.get_layer(\"main_output\").output)\n",
    "prediction = new_model.predict({'main_input': headline_data})\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.9604645e-08],\n",
       "       [0.0000000e+00],\n",
       "       [1.0494286e-01],\n",
       "       [0.0000000e+00],\n",
       "       [9.9839771e-01],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [6.6406488e-01],\n",
       "       [2.9802322e-08],\n",
       "       [0.0000000e+00],\n",
       "       [8.9902139e-01],\n",
       "       [0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference:https://github.com/keras-team/keras/issues/2766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
